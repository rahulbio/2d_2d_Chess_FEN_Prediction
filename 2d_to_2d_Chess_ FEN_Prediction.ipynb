{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peAl07A1RUmE"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdtUxcO9ONKI"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkLVeD6oP60f"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHl43c1yQoRt"
      },
      "outputs": [],
      "source": [
        "!cp /content/kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xl1KK1PQTvIt"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYlWTsM2RstW"
      },
      "outputs": [],
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzj0a3HWRvQV"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d koryakinp/chess-positions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxvlhXaeTpmC"
      },
      "outputs": [],
      "source": [
        "!unzip chess-positions.zip -d /content/Datas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHnlVfaSLfZT"
      },
      "outputs": [],
      "source": [
        "\n",
        "import re\n",
        "import cv2\n",
        "import glob\n",
        "import random as rd\n",
        "import warnings\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.metrics import confusion_matrix,f1_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from imutils import paths\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsOMqILALfZV"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "train_path = glob.glob(r\"/content/Datas/train/*.jpeg\")\n",
        "test_path = glob.glob(r\"/content/Datas/test/*.jpeg\")\n",
        "\n",
        "rd.shuffle(train_path)\n",
        "rd.shuffle(test_path)\n",
        "\n",
        "train_size = 8000\n",
        "test_size = 2000\n",
        "train = train_path[:train_size]\n",
        "test= test_path[:test_size]\n",
        "print(len(train))\n",
        "print(len(test))\n",
        "\n",
        "piece_symbols = 'prbnkqPRBNKQ'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67E0Y9-SLfZX"
      },
      "outputs": [],
      "source": [
        "def get_image_FEN_label(image_path):\n",
        "    fen_label= image_path.replace('.jpeg', '').split('/')[-1]\n",
        "    fen_label = fen_label.replace('train\\\\', '')\n",
        "    return fen_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxNLeeuILfZX"
      },
      "outputs": [],
      "source": [
        "rand = np.random.randint(0, train_size)\n",
        "img_path = train[rand]\n",
        "print(img_path)\n",
        "img_moves = get_image_FEN_label(img_path)\n",
        "print(img_moves)\n",
        "img_rand = cv2.imread(img_path)\n",
        "plt.imshow(cv2.cvtColor(img_rand, cv2.COLOR_BGR2RGB))\n",
        "plt.title(img_moves)\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYoxyuc7Vl9n"
      },
      "outputs": [],
      "source": [
        "!pip install chess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76LkPRYwLfZY"
      },
      "outputs": [],
      "source": [
        "import chess.svg\n",
        "import chess\n",
        "print(\"The FEN notation of the image is: \", img_moves)\n",
        "board = chess.Board(img_moves.replace('-', '/'))\n",
        "chess.svg.board(board, size=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_S10Vs3LfZZ"
      },
      "outputs": [],
      "source": [
        "samples =rd.sample(train, 9)\n",
        "fig = plt.figure(figsize=(11, 11))\n",
        "columns = 3\n",
        "rows = 3\n",
        "for i, img in zip(range(1, columns*rows +1),samples ):\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    img_moves =  get_image_FEN_label(img)\n",
        "    img = cv2.imread(img)\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.title(img_moves)\n",
        "    plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L49g2MwZLfZa"
      },
      "outputs": [],
      "source": [
        "ratios = []\n",
        "widths = []\n",
        "heights = []\n",
        "\n",
        "for img in train:\n",
        "  img= cv2.imread(img)\n",
        "  ratios.append(img.shape[1] / img.shape[0])\n",
        "  heights.append(img.shape[0])\n",
        "  widths.append(img.shape[1])\n",
        "\n",
        "fig, (ax1,ax2,ax3) = plt.subplots(1, 3, figsize=(12, 5))\n",
        "\n",
        "ax1.hist(ratios, bins=50)\n",
        "ax1.set_xlabel('ratio')\n",
        "ax1.set_ylabel('count')\n",
        "ax1.set_title('Average ratio: {}'.format(np.mean(ratios)))\n",
        "\n",
        "ax2.hist(widths, bins=50)\n",
        "ax2.set_xlabel('width')\n",
        "ax2.set_ylabel('count')\n",
        "ax2.set_title('Average width: {}'.format(np.mean(widths)))\n",
        "\n",
        "ax3.hist(heights, bins=50)\n",
        "ax3.set_xlabel('height')\n",
        "ax3.set_ylabel('count')\n",
        "ax3.set_title('Average height: {}'.format(np.mean(heights)))\n",
        "\n",
        "print(\"Selected Width X heights: {}X{}\".format(int(np.mean(widths)) ,int(np.mean(heights))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRIIkr_OLfZa"
      },
      "outputs": [],
      "source": [
        "def preprocess_some_images(img_paths, width, height):\n",
        "  resized_imgs = []\n",
        "  for img_path in img_paths:\n",
        "    img = cv2.imread(img_path, cv2.COLOR_BGR2GRAY)\n",
        "    gray_image = cv2.resize(img, (width, height))\n",
        "    gray_image =(gray_image - np.min(gray_image)) / (np.max(gray_image) - np.min(gray_image))\n",
        "    resized_imgs.append(gray_image)\n",
        "  return resized_imgs\n",
        "preprocessed_imgs= preprocess_some_images(samples,240,240)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZ-yrMysLfZb"
      },
      "outputs": [],
      "source": [
        "\"{}X{}\".format(preprocessed_imgs[0].shape[0],preprocessed_imgs[0].shape[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBkwWDdfLfZb"
      },
      "outputs": [],
      "source": [
        "preprocessed_imgs[0].shape\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=15)\n",
        "img_transformed = pca.fit_transform(new_img)\n",
        "\n",
        "percentage_var_explained = pca.explained_variance_ / np.sum(pca.explained_variance_)\n",
        "cum_var_explained = np.cumsum(percentage_var_explained)\n",
        "\n",
        "reserved = np.round(np.sum(pca.explained_variance_ratio_), 3) * 100\n",
        "print(\"Using {} components reserves {}% of the features\".format(pca.n_components, reserved))\n",
        "\n",
        "x_vals = np.arange(pca.n_components + 1)\n",
        "y_vals = np.insert(cum_var_explained, 0, 0)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(x_vals, y_vals, linewidth=2)\n",
        "plt.grid(True)\n",
        "plt.xlabel('n_components')\n",
        "plt.ylabel('Cumulative_explained_variance')\n",
        "\n",
        "plt.xlim(0, pca.n_components)\n",
        "plt.ylim(0, 1.0)\n",
        "\n",
        "plt.axhline(y=reserved / 100.0, linestyle='--', color='k', linewidth=2)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WXP94zu4cLlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjHdH3IlLfZd"
      },
      "outputs": [],
      "source": [
        "fig, (ax1,ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "img = np.array(cv2.imread(samples[8]))\n",
        "new_img=img.reshape(img.shape[0], (img.shape[1]*img.shape[2]))\n",
        "new_img= cv2.resize(new_img, (720, 720),interpolation=cv2.INTER_CUBIC)\n",
        "ax1.imshow(new_img, cmap='gray')\n",
        "ax1.set_title(\"Before PCA image\")\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "temp = pca.inverse_transform(img_transformed)\n",
        "temp = np.reshape(temp, (720,720))\n",
        "ax2.imshow(temp, cmap='gray')\n",
        "ax2.set_title(\"After PCA image\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHTDU0clbWZB"
      },
      "outputs": [],
      "source": [
        "pip install visualkeras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88hCVZsULfZd"
      },
      "outputs": [],
      "source": [
        "def image_to_squares_pca(img,heights,widths):\n",
        "  squares = []\n",
        "  for i in range(0,8):\n",
        "    for j in range(0,8):\n",
        "      new_img =img[i*heights//8:i*heights//8+heights//8,j*widths//8:j*widths//8+widths//8]\n",
        "      new_img=new_img.reshape(new_img.shape[0], (new_img.shape[1]*new_img.shape[2]))\n",
        "      new_img= cv2.resize(new_img, (720, 720),interpolation=cv2.INTER_CUBIC)\n",
        "      squares.append(new_img)\n",
        "  return np.array(squares)\n",
        "\n",
        "img = np.array(cv2.imread(samples[8]))\n",
        "sqaures= image_to_squares_pca(img,200,200)\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "columns = 8\n",
        "rows = 8\n",
        "for i, img in zip(range(1, columns*rows +1),sqaures):\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "plt.show()\n",
        "sqaures.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rz9LUzm3LfZe"
      },
      "outputs": [],
      "source": [
        "def image_to_squares(img,heights,widths):\n",
        "  squares = []\n",
        "  for i in range(0,8):\n",
        "    for j in range(0,8):\n",
        "      squares.append(img[i*heights//8:i*heights//8+heights//8,j*widths//8:j*widths//8+widths//8])\n",
        "  return np.array(squares)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gtb8Tjt2LfZe"
      },
      "outputs": [],
      "source": [
        "sqaures= image_to_squares(preprocessed_imgs[0],240,240)\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "columns = 8\n",
        "rows = 8\n",
        "for i, img in zip(range(1, columns*rows +1),sqaures):\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "plt.show()\n",
        "sqaures.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r93FLYCCLfZe"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(img_path):\n",
        "    height =240\n",
        "    width =240\n",
        "    img = cv2.imread(img_path, cv2.COLOR_BGR2GRAY)\n",
        "    gray_image = cv2.resize(img, (width, height))\n",
        "    gray_image =(gray_image - np.min(gray_image)) / (np.max(gray_image) - np.min(gray_image))\n",
        "\n",
        "    squares = image_to_squares(gray_image,height,width)\n",
        "    return squares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hM15f_bHLfZe"
      },
      "outputs": [],
      "source": [
        "sqaures=preprocess_image(train[444])\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "columns = 8\n",
        "rows = 8\n",
        "for i, img in zip(range(1, columns*rows +1),sqaures):\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "plt.show()\n",
        "sqaures.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QU0K4-HKLfZg"
      },
      "outputs": [],
      "source": [
        "def onehot_from_fen(fen):\n",
        "    eye = np.eye(13)\n",
        "    output = np.empty((0, 13))\n",
        "    fen = re.sub('[-]', '', fen)\n",
        "\n",
        "    for char in fen:\n",
        "        if char in '12345678':\n",
        "              output = np.append(output, np.tile(eye[12], (int(char), 1)), axis=0)\n",
        "        else:\n",
        "              if char in piece_symbols:\n",
        "                 idx = piece_symbols.index(char)\n",
        "                 output = np.append(output, eye[idx].reshape((1, 13)), axis=0)\n",
        "              else:\n",
        "                pass\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def fen_from_onehot(one_hot):\n",
        "    output = ''\n",
        "    for j in range(8):\n",
        "        for i in range(8):\n",
        "            if(one_hot[j][i] == 12):\n",
        "                output += ' '\n",
        "            else:\n",
        "                output += piece_symbols[one_hot[j][i]]\n",
        "        if(j != 7):\n",
        "            output += '-'\n",
        "\n",
        "    for i in range(8, 0, -1):\n",
        "        output = output.replace(' ' * i, str(i))\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxnbQISZLfZh"
      },
      "outputs": [],
      "source": [
        "def train_gen(features):\n",
        "    for i, img in enumerate(features):\n",
        "        y = onehot_from_fen(get_image_FEN_label(img))\n",
        "        x = preprocess_image(img)\n",
        "        yield x, y\n",
        "\n",
        "def pred_gen(features):\n",
        "    for i, img in enumerate(features):\n",
        "        y = onehot_from_fen(get_image_FEN_label(img))\n",
        "        x = preprocess_image(img)\n",
        "        yield x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFIwR0Y5LfZh"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "# Add a convolutional layer\n",
        "model = Sequential()\n",
        "model.add(Convolution2D(32, (3, 3),activation='relu', input_shape=(30, 30, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "model.add(Convolution2D(16, (5, 5),activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.35))\n",
        "model.add(Dense(13, activation='softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ue3V_dnLfZh"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PZyAC4ZJLfZi"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "hist = model.fit_generator(train_gen(train), steps_per_epoch=250, epochs=30,validation_data=pred_gen(test), validation_steps=30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feIz3JfYLfZi"
      },
      "outputs": [],
      "source": [
        "model.save(\"content/datas/chess_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFD7cE3LLDrz"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(15, 5))\n",
        "plt.plot(hist.history['val_loss'], label='(test data)')\n",
        "plt.plot(hist.history['loss'], label='(train data)')\n",
        "plt.ylabel('value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.title('Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WY-RI_IlLfZj"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.plot(hist.history['val_accuracy'], label='(test data)')\n",
        "plt.plot(hist.history['accuracy'], label='(train data)')\n",
        "\n",
        "plt.ylabel('value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.title('Validation Accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyP1rfJVLfZj"
      },
      "outputs": [],
      "source": [
        "res = (\n",
        "  model.predict_generator(pred_gen(test), steps=test_size)\n",
        "  .argmax(axis=1)\n",
        "  .reshape(-1, 8, 8)\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bt4uMTqoLfZk"
      },
      "outputs": [],
      "source": [
        "pred_fens = np.array([fen_from_onehot(one_hot) for one_hot in res])\n",
        "test_fens = np.array([get_image_FEN_label(fn) for fn in test])\n",
        "\n",
        "final_accuracy = 100*(pred_fens == test_fens).astype(float).mean()\n",
        "\n",
        "print(\"Testing Accuracy: {:1.2f}%\".format(final_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-Q0sEAQLfZk"
      },
      "outputs": [],
      "source": [
        "print(\"\\nConfusion Matrix:\\n------------------------\")\n",
        "confusion_matrix(test_fens, pred_fens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFwdwTKdgS8Q"
      },
      "outputs": [],
      "source": [
        "model.save(\"content/datas/chess_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeGH0zOGLfZk"
      },
      "outputs": [],
      "source": [
        "import matplotlib.image as mpimg\n",
        "def display_with_predicted_fen(image):\n",
        "    plt.figure(figsize=(5,5))\n",
        "    pred = model.predict(preprocess_image(image)).argmax(axis=1).reshape(-1, 8, 8)\n",
        "    fen = fen_from_onehot(pred[0])\n",
        "    imgplot = plt.imshow(mpimg.imread(image))\n",
        "    plt.axis('off')\n",
        "    plt.title(fen)\n",
        "    plt.show()\n",
        "    return fen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32HbSYAsK30c"
      },
      "outputs": [],
      "source": [
        "model.save(\"content/datas/chess_modelll.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ff8xrmNJLfZk"
      },
      "outputs": [],
      "source": [
        "image_path = \"/content/testing_img\"\n",
        "\n",
        "\n",
        "predicted_fen_score=display_with_predicted_fen(image_path)\n",
        "print(\"predicted FEN :\",predicted_fen_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5elX_T6TLfZl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}